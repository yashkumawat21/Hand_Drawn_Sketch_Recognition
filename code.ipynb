{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Sketchy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yncf4_p5vbRO",
        "outputId": "0f8eb27d-439e-4e24-9dcf-f857a9e71d23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPTPLLLuyhn2",
        "outputId": "a4c91326-401f-43db-fa9a-48e61ed34e72"
      },
      "source": [
        "#To extract the rar file\n",
        "\n",
        "!pip install RarFile\n",
        "\n",
        "from rarfile import RarFile\n",
        "\n",
        "with RarFile(\"/content/drive/MyDrive/sketchy_dataset/10Classes.rar\") as rf:\n",
        "    rf.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting RarFile\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f4/c92fab227c7457e3b76a4096ccb655ded9deac869849cb03afbe55dfdc1e/rarfile-4.0-py3-none-any.whl\n",
            "Installing collected packages: RarFile\n",
            "Successfully installed RarFile-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNPGU-qgVEnF"
      },
      "source": [
        "# Reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLjhSQ60zjuX"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A0tqGfvyx6h",
        "outputId": "5fca07d0-9735-4f23-cfff-0a050c39ba89"
      },
      "source": [
        "completeData = tf.keras.preprocessing.image_dataset_from_directory('/content/10Classes', \n",
        "                                                                    labels='inferred', \n",
        "                                                                    label_mode='categorical',\n",
        "                                                                    batch_size=32,\n",
        "                                                                    image_size=(224, 224), \n",
        "                                                                    seed=3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5672 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aXx7B52zrt9",
        "outputId": "81cd9193-db2a-4b03-de94-30928ac69cac"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "\n",
        "for td in completeData:\n",
        "  for tx in td[0]:\n",
        "    X.append(tx)\n",
        "  for ty in td[1]:\n",
        "    Y.append(ty)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5672, 224, 224, 3) (5672, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksqlU0y9cajz"
      },
      "source": [
        "# Extracting features from images using pretrained VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j053oJXb6Ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158e7c31-ceff-42ed-9cc5-3c4a74335445"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import Model\n",
        "\n",
        "model = VGG16()\n",
        "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "\n",
        "features = model.predict(X, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKLi54DacJFy",
        "outputId": "96a7583a-2f10-4b84-8740-14beeaf65aa1"
      },
      "source": [
        "features.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5672, 4096), (5672, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCYEEl8NchVr"
      },
      "source": [
        "# Reducing Dimensionality of the Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8VgJUY2clR6"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=100, random_state=22)\n",
        "pca.fit(features)\n",
        "x = pca.transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRULh3lQcxey",
        "outputId": "79feb40f-d81c-4030-920e-9690ebf5b6c8"
      },
      "source": [
        "x.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5672, 100), (5672, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huZPlF-mW0aI"
      },
      "source": [
        "# Standarizing the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C_TmLsYW4nR"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(x)\n",
        "x_std = sc.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3oRQE8HV0Kg"
      },
      "source": [
        "# Splitting Dataset into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLO09XqbrMz9",
        "outputId": "1d54b687-8428-4c16-f2e8-a54332fca512"
      },
      "source": [
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(x_std, Y, shuffle=True, test_size=0.2, random_state = 3)\n",
        "\n",
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4537, 100) (4537, 10) (1135, 100) (1135, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lBe0KZmMmjQ"
      },
      "source": [
        "# Using RandomForestClassifier over our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXchDq7tr7Rt",
        "outputId": "8e88bb2a-82ff-4d19-8104-30ca4ee2c8fc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators = 7)  \n",
        "  \n",
        "clf.fit(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=7,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WycYhW6nz1g-",
        "outputId": "693a08aa-aa76-49d4-89fb-cd2b8fe259f1"
      },
      "source": [
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(test_x)\n",
        "  \n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics  \n",
        "print()\n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(test_y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ACCURACY OF THE MODEL:  0.5427312775330396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPQ8avU6MqLX"
      },
      "source": [
        "# Using Naive Bayes over our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2PofZT9USXd",
        "outputId": "8a22d73a-b26f-4c2a-fe0e-5f02a5adb82c"
      },
      "source": [
        "train_x.shape, train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4537, 100), (4537, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ePaEGNYJf6"
      },
      "source": [
        "labels = np.argmax(train_y, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SynG7k3wMstU"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import model_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9379T-FWoD6",
        "outputId": "d1f2d59c-61d8-4401-a79f-2a45f675709c"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "scores = model_selection.cross_val_score(gnb, train_x, labels, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Mean Score\", scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Score 0.7954628464852421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p4ahJ5GWUGF"
      },
      "source": [
        "# Using SVM classifier over the given dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYSPZXpvWXzk",
        "outputId": "75e55000-40fa-49d3-98d6-6d6318d00aec"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Training a SVM classifier using SVC class\n",
        "svm = SVC(kernel= 'rbf', random_state=1, C=0.1)\n",
        "svm.fit(train_x, labels)\n",
        " \n",
        "# Mode performance\n",
        "y_labels = np.argmax(test_y, axis=1)\n",
        "y_pred = svm.predict(test_x)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_labels, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLXlmPzXc_ss"
      },
      "source": [
        "# Now trying the models on custom images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqEtMXJkwlzk"
      },
      "source": [
        "import cv2 \n",
        "\n",
        "def read_image(file):\n",
        "  originalImage = cv2.imread(file)\n",
        "  img = cv2.resize(originalImage, (224,224), interpolation=cv2.INTER_AREA)\n",
        "  img = np.array([img])\n",
        "  print(img.shape)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXn0ZeprxV1o"
      },
      "source": [
        "def return_reduced_features(model_vgg, img):\n",
        "  feat = model_vgg.predict(img)\n",
        "  x = pca.transform(feat)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f461OU-8yNNL"
      },
      "source": [
        "def predict_model(model, x):\n",
        "  pred = model.predict(x)\n",
        "  return np.argmax(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VpOLHNngJ1u"
      },
      "source": [
        "def get_label(model, image_path, model_vgg):\n",
        "  img = read_image(image_path)\n",
        "  x = return_reduced_features(model_vgg, img)\n",
        "  pred = predict_model(model, x)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ENxl6DpZoa5"
      },
      "source": [
        "# Now let's use a Neural Network to do all of this but with more number of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8neCsIKbA-L"
      },
      "source": [
        "with RarFile(\"/content/drive/MyDrive/sketchy_dataset/Small.rar\") as rf:\n",
        "    rf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWjQpN30aezX",
        "outputId": "39d36333-632f-4253-ebc7-97658e54c9cd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "bigDataset = tf.keras.preprocessing.image_dataset_from_directory('/content/Small', \n",
        "                                                                    labels='inferred', \n",
        "                                                                    label_mode='categorical',\n",
        "                                                                    batch_size=32,\n",
        "                                                                    image_size=(224, 224), \n",
        "                                                                    validation_split=0.5,   \n",
        "                                                                    subset='training',\n",
        "                                                                    seed=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13949 files belonging to 24 classes.\n",
            "Using 6975 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AsYqlkFa9_H",
        "outputId": "75d2d9fb-4e3d-4d2a-b7f3-be216b38145b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "\n",
        "for td in bigDataset:\n",
        "  for tx in td[0]:\n",
        "    X.append(tx)\n",
        "  for ty in td[1]:\n",
        "    Y.append(ty)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6975, 224, 224, 3) (6975, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9q0vMurbN-7"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import Model\n",
        "\n",
        "model_vgg = VGG16()\n",
        "model_vgg = Model(inputs = model_vgg.inputs, outputs = model_vgg.layers[-2].output)\n",
        "\n",
        "features = model_vgg.predict(X, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVKuWwK6cvnZ",
        "outputId": "ae7abd0a-5931-4844-cfeb-da2ea7c6a889"
      },
      "source": [
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(features, Y, shuffle=True, test_size=0.2, random_state = 3)\n",
        "\n",
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5580, 4096) (5580, 24) (1395, 4096) (1395, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNVDSIX-baiZ",
        "outputId": "97d95c1f-9f52-468d-e34a-2d5ba8c8c421"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "\n",
        "# Creating a Simple Dense Network \n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=train_x.shape[1:]))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(24, activation='softmax')) \n",
        "# Train model\n",
        "adam = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 4,788,888\n",
            "Trainable params: 4,788,888\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ghr-i1dAqH",
        "outputId": "0ccc5341-5727-45d6-c7aa-a42dad053c44"
      },
      "source": [
        "model.fit(train_x, train_y, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 - 1s - loss: 2.2912 - top_k_categorical_accuracy: 0.6780 - val_loss: 1.2248 - val_top_k_categorical_accuracy: 0.9158\n",
            "Epoch 2/5\n",
            "20/20 - 0s - loss: 1.2343 - top_k_categorical_accuracy: 0.9072 - val_loss: 0.9307 - val_top_k_categorical_accuracy: 0.9391\n",
            "Epoch 3/5\n",
            "20/20 - 0s - loss: 0.9609 - top_k_categorical_accuracy: 0.9401 - val_loss: 0.8174 - val_top_k_categorical_accuracy: 0.9444\n",
            "Epoch 4/5\n",
            "20/20 - 0s - loss: 0.7810 - top_k_categorical_accuracy: 0.9598 - val_loss: 0.7538 - val_top_k_categorical_accuracy: 0.9624\n",
            "Epoch 5/5\n",
            "20/20 - 0s - loss: 0.6631 - top_k_categorical_accuracy: 0.9729 - val_loss: 0.6811 - val_top_k_categorical_accuracy: 0.9624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7236067590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lY9-yxsdG07",
        "outputId": "00f3ae11-7c07-468e-c7cd-ff80578cbf8d"
      },
      "source": [
        "score = model.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 96.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7EmOkh4jSyu"
      },
      "source": [
        "# Predicting on custom image using this nn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArR6RGc1hwIH",
        "outputId": "a12b3aa3-2681-47cf-fcb6-326d0d6522d2"
      },
      "source": [
        "import cv2 \n",
        " \n",
        "originalImage = cv2.imread('star.png')\n",
        "img = cv2.resize(originalImage, (224,224), interpolation=cv2.INTER_AREA)\n",
        "img = np.array([img])\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-wvM76wiNvY",
        "outputId": "ab1122e0-35a0-47f5-bb2c-4df913ff9626"
      },
      "source": [
        "feat = model_vgg.predict(img)\n",
        "\n",
        "pred = model.predict(feat)\n",
        "np.argmax(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}